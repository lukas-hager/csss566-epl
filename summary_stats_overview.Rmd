---
title: "Basic Overview of EPL Data"
author: "Lukas Hager"
date: "5/4/2022"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list = ls())

gc()
gc()

library(data.table)
library(rmarkdown)
library(janitor)
library(tidyverse)

options(dplyr.summarise.inform = FALSE)
```

## General Information
___

### Data Import 

To ensure that we don't omit any observations, we can read in each individual file and combine them:

```{r}
data_og <- bind_rows(
  lapply(list.files('/Users/hlukas/Google Drive/Raw Data/EPL/Datasets',
                    full.names = TRUE,
                    pattern = '\\d{4}\\-\\d{2}\\.csv'),
         read_csv,
         col_types = cols())
) %>% 
  janitor::clean_names() %>% 
  mutate(date = as.Date(date, '%d/%m/%y'))
```

### Summary Statistics

```{r, results='asis'}
cat(str_interp('There are ${nrow(data_og)} observations in the data.'))
```

We should confirm the level of granularity in the data:

```{r}
data_og %>% 
  select(date, home_team, away_team) %>% 
  distinct() %>% 
  nrow()
```

So we know that each observation is a match. Let's look at matches by year:

```{r}
data_og %>% 
  mutate(year = year(date)) %>% 
  group_by(year) %>% 
  summarise(n = n()) %>% 
  ungroup() %>% 
  arrange(year)
```

This is kind of weird -- there are theoretically 380 EPL matches each year, so anything below that is odd, and anything above that (2012, 2017, 2020) is also strange. *TODO Analysis*

We also want to know number of bookmakers by match, so we need to reshape the data (I'm also combining a step to get the implied odds from the bookmakers):

```{r}
data_og %>% 
  select(date:bsa) %>% 
  pivot_longer(b365h:bsa) %>% 
  mutate(pred_result = str_sub(name, -1),
         bookmaker = str_sub(name, 1, -2),
         value = 1/value) %>% 
  # divide by sum to remove vig
  group_by(date, home_team, away_team, bookmaker) %>% 
  mutate(value = value / sum(value)) %>% 
  ungroup() %>% 
  select(-name) %>% 
  pivot_wider(names_from = pred_result,
              values_from = value) %>% 
  group_by(date, home_team, away_team) %>% 
  summarise(n_bookmakers = sum(!is.na(h))) %>% 
  ungroup() %>% 
  group_by(year = year(date)) %>% 
  summarise(min = min(n_bookmakers),
            mean = mean(n_bookmakers),
            median = median(n_bookmakers),
            max = max(n_bookmakers)) %>% 
  ungroup() %>% 
  arrange(year)
```

So it looks like some of the bookmakers fade in and out of the sample, with the best coverage from 2009-2011. Effectively, it seems like the most viable subset is from 2009-2018.